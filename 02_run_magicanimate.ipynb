{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run magicAnimate\n",
    "Run MagicAnimate with 2 control nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# keep the path of this folder\n",
    "os.chdir(\"/media/test/D/Ashok_Batakala_folder/Mtech_Project/\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/manimate/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MagicAnimate Pipeline...\n",
      "loaded temporal unet's pretrained weights from pretrained_models/stable-diffusion-v1-5/unet ...\n",
      "### missing keys: 560; \n",
      "### unexpected keys: 0;\n",
      "### Temporal Module Parameters: 417.1376 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'addition_embed_type': None, 'addition_embed_type_num_heads': 64, 'addition_time_embed_dim': None, 'conditioning_channels': 3, 'encoder_hid_dim': None, 'encoder_hid_dim_type': None, 'global_pool_conditions': False, 'num_attention_heads': None, 'transformer_layers_per_block': 1} were passed to ControlNetModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "It is recommended to provide `attention_head_dim` when calling `get_down_block`. Defaulting `attention_head_dim` to 8.\n",
      "It is recommended to provide `attention_head_dim` when calling `get_down_block`. Defaulting `attention_head_dim` to 8.\n",
      "It is recommended to provide `attention_head_dim` when calling `get_down_block`. Defaulting `attention_head_dim` to 8.\n",
      "It is recommended to provide `attention_head_dim` when calling `get_down_block`. Defaulting `attention_head_dim` to 8.\n",
      "It is recommended to provide `attention_head_dim` when calling `get_down_block`. Defaulting `attention_head_dim` to 8.\n",
      "It is recommended to provide `attention_head_dim` when calling `get_down_block`. Defaulting `attention_head_dim` to 8.\n",
      "It is recommended to provide `attention_head_dim` when calling `get_down_block`. Defaulting `attention_head_dim` to 8.\n",
      "It is recommended to provide `attention_head_dim` when calling `get_down_block`. Defaulting `attention_head_dim` to 8.\n",
      "/media/test/D/Ashok_Batakala_folder/Mtech_Project/magicanimate/pipelines/pipeline_animation.py:105: FutureWarning: The configuration file of this scheduler: DDIMScheduler {\n",
      "  \"_class_name\": \"DDIMScheduler\",\n",
      "  \"_diffusers_version\": \"0.21.4\",\n",
      "  \"beta_end\": 0.012,\n",
      "  \"beta_schedule\": \"linear\",\n",
      "  \"beta_start\": 0.00085,\n",
      "  \"clip_sample\": true,\n",
      "  \"clip_sample_range\": 1.0,\n",
      "  \"dynamic_thresholding_ratio\": 0.995,\n",
      "  \"num_train_timesteps\": 1000,\n",
      "  \"prediction_type\": \"epsilon\",\n",
      "  \"rescale_betas_zero_snr\": false,\n",
      "  \"sample_max_value\": 1.0,\n",
      "  \"set_alpha_to_one\": true,\n",
      "  \"steps_offset\": 0,\n",
      "  \"thresholding\": false,\n",
      "  \"timestep_spacing\": \"leading\",\n",
      "  \"trained_betas\": null\n",
      "}\n",
      " is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file\n",
      "  deprecate(\"steps_offset!=1\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/media/test/D/Ashok_Batakala_folder/Mtech_Project/magicanimate/pipelines/pipeline_animation.py:118: FutureWarning: The configuration file of this scheduler: DDIMScheduler {\n",
      "  \"_class_name\": \"DDIMScheduler\",\n",
      "  \"_diffusers_version\": \"0.21.4\",\n",
      "  \"beta_end\": 0.012,\n",
      "  \"beta_schedule\": \"linear\",\n",
      "  \"beta_start\": 0.00085,\n",
      "  \"clip_sample\": true,\n",
      "  \"clip_sample_range\": 1.0,\n",
      "  \"dynamic_thresholding_ratio\": 0.995,\n",
      "  \"num_train_timesteps\": 1000,\n",
      "  \"prediction_type\": \"epsilon\",\n",
      "  \"rescale_betas_zero_snr\": false,\n",
      "  \"sample_max_value\": 1.0,\n",
      "  \"set_alpha_to_one\": true,\n",
      "  \"steps_offset\": 1,\n",
      "  \"thresholding\": false,\n",
      "  \"timestep_spacing\": \"leading\",\n",
      "  \"trained_betas\": null\n",
      "}\n",
      " has not set the configuration `clip_sample`. `clip_sample` should be set to False in the configuration file. Please make sure to update the config accordingly as not setting `clip_sample` in the config might lead to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file\n",
      "  deprecate(\"clip_sample not set\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization Done!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import imageio\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "from demo.animate import MagicAnimate\n",
    "\n",
    "animator = MagicAnimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def animate(*args, **kwargs):\n",
    "#     print(\"running animate\")\n",
    "#     return animator(*args, **kwargs)\n",
    "\n",
    "# Define a function to read a video file\n",
    "def read_video(video):\n",
    "    reader = imageio.get_reader(video)\n",
    "    fps = reader.get_meta_data()['fps']\n",
    "    return video\n",
    "\n",
    "# Define a function to read an image file\n",
    "def read_image(image, size=512):\n",
    "    return np.array(Image.fromarray(image).resize((size, size)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. To run single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inputs\n",
    "reference_image_path = \"/media/test/D/Ashok_Batakala_folder/Ashok_temp_data/tiktok_d/images/1323.png\"\n",
    "motion_sequence_path = \"/media/test/D/Ashok_Batakala_folder/Ashok_temp_data/tiktok_d/seg_thin_08.mp4\"\n",
    "\n",
    "motion_sequence_path_keypoints = \"/media/test/D/Ashok_Batakala_folder/Ashok_temp_data/tiktok_d/keypoints_conditioning_video.mp4\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from get_keypoints import Openpose_detector_class \n",
    "# openpose_detector = Openpose_detector_class()\n",
    "# openpose_detector(reference_image_path, \"/media/test/D/Ashok_Batakala_folder/Mtech_Project/DATA/01_trail_2/seg_videos/image_000012_keypoints.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example inputs\n",
    "# reference_image_path = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/sample_datapoint/demo4.png\"\n",
    "# motion_sequence_path = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/sample_datapoint/demo4.mp4\"\n",
    "# motion_sequence_path_keypoints = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/sample_datapoint/control_keypoint_demo4.mp4\"\n",
    "\n",
    "random_seed = 1\n",
    "sampling_steps = 25\n",
    "guidance_scale = 7.5\n",
    "controlnet_weights = [1,1] # segmentation mask, keypoints\n",
    "\n",
    "# Read the reference image and motion sequence\n",
    "reference_image = read_image(np.array(Image.open(reference_image_path)))\n",
    "motion_sequence = read_video(motion_sequence_path)\n",
    "motion_sequence_keypoints = read_video(motion_sequence_path_keypoints)\n",
    "\n",
    "result = animator(reference_image, motion_sequence, random_seed, sampling_steps, guidance_scale,\n",
    "                  motion_sequence_keypoints=motion_sequence_keypoints,\n",
    "                    controlnet_weights=controlnet_weights,\n",
    "                    save_only_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. running with folder in loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/images'\n",
    "image_names = os.listdir(images_folder)\n",
    "\n",
    "results_folder = '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/results_fat'\n",
    "seg_videos_folder = '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/seg_fat_n08'\n",
    "keypoint_videos_folder = '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/keypoint_images_only_face_hands'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video path already exists, deleting it\n",
      "Video path already exists, deleting it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, png_pipe, from '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/seg_fat_n08/rajinikanth.png':\n",
      "  Duration: N/A, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 512x512 [SAR 3937:3937 DAR 1:1], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> mpeg4 (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/seg_fat_n08_videos/rajinikanth.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p(tv, progressive), 512x512 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 mpeg4\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
      "frame=   13 fps=0.0 q=1.6 Lsize=      40kB time=00:00:00.48 bitrate= 684.0kbits/s speed=5.59x      \n",
      "video:39kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.379527%\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, png_pipe, from '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/seg_fat_n08/Black.png':\n",
      "  Duration: N/A, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 511x512 [SAR 3937:3937 DAR 511:512], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> mpeg4 (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[mpeg4 @ 0x588710c7b7c0] Invalid pixel aspect ratio 511/512, limit is 255/255 reducing\n",
      "Output #0, mp4, to '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/seg_fat_n08_videos/Black.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p(tv, progressive), 512x512 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, SAR 511:512 DAR 511:512, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 mpeg4\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
      "frame=   13 fps=0.0 q=1.6 Lsize=      33kB time=00:00:00.48 bitrate= 561.4kbits/s speed=5.86x     \n",
      "video:32kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.914401%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos created in /home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/seg_fat_n08_videos\n",
      "Video path already exists, deleting it\n",
      "Video path already exists, deleting it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/keypoint_images_only_face_hands/Black.jpg':\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: 1331 kb/s\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 512x512 [SAR 1:1 DAR 1:1], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> mpeg4 (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x648012507780] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, mp4, to '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/keypoint_images_only_face_hands_videos/Black.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p(tv, bt470bg/unknown/unknown, progressive), 512x512 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 mpeg4\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
      "frame=   13 fps=0.0 q=1.6 Lsize=      16kB time=00:00:00.48 bitrate= 269.6kbits/s speed=8.25x    \n",
      "video:15kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 6.266833%\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/keypoint_images_only_face_hands/rajinikanth.jpg':\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: 1549 kb/s\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 512x512 [SAR 1:1 DAR 1:1], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> mpeg4 (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x5c76af7b1000] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, mp4, to '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/keypoint_images_only_face_hands_videos/rajinikanth.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p(tv, bt470bg/unknown/unknown, progressive), 512x512 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 mpeg4\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
      "frame=    1 fps=0.0 q=3.7 size=       0kB time=00:00:00.00 bitrate=4512.8kbits/s speed=N/A    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos created in /home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/keypoint_images_only_face_hands_videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=   13 fps=0.0 q=1.6 Lsize=      19kB time=00:00:00.48 bitrate= 326.3kbits/s speed=8.54x    \n",
      "video:18kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 5.121323%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#============ pre-processing ============\n",
    "# if seg,keypoints are images and not videos then convert them to videos\n",
    "\n",
    "#check if images are there in the folder. pick a file. see if ends with mp4 or not. if not then convert to video\n",
    "random_file = os.listdir(seg_videos_folder)[0]\n",
    "if not random_file.endswith('.mp4'):\n",
    "    seg_images_dir = seg_videos_folder\n",
    "    seg_videos_folder = seg_videos_folder+'_videos'\n",
    "    from ashok_utils.video_utils import image_to_video_folder \n",
    "    image_to_video_folder(seg_images_dir, seg_videos_folder, time=0.5)\n",
    "    \n",
    "random_file = os.listdir(keypoint_videos_folder)[0]\n",
    "if not random_file.endswith('.mp4'):\n",
    "    keypoint_images_dir = keypoint_videos_folder\n",
    "    keypoint_videos_folder = keypoint_videos_folder+'_videos'\n",
    "    from ashok_utils.video_utils import image_to_video_folder \n",
    "    image_to_video_folder(keypoint_images_dir, keypoint_videos_folder, time=0.5)\n",
    "\n",
    "\n",
    "#create results folder if not exists\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/test/D/Ashok_Batakala_folder/Mtech_Project/magicanimate/pipelines/pipeline_animation.py:650: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet3DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet3DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  num_channels_latents = self.unet.in_channels\n",
      "100%|██████████| 25/25 [00:33<00:00,  1.35s/it]\n",
      "100%|██████████| 16/16 [00:00<00:00, 17.85it/s]\n",
      "100%|██████████| 25/25 [00:34<00:00,  1.40s/it]\n",
      "100%|██████████| 16/16 [00:00<00:00, 17.45it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for image_name in image_names: \n",
    "    # # Example inputs\n",
    "    # reference_image_path = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/lab_presentation/lady_standing_540.jpg\"\n",
    "    # motion_sequence_path = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/lab_presentation/seg_videos/segmentation_mask_fat_1.mp4\"\n",
    "    # motion_sequence_path_keypoints = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/lab_presentation/lady_standing_resized_keypoints_540.mp4\"\n",
    "    \n",
    "    reference_image_path = os.path.join(images_folder, image_name)\n",
    "    motion_sequence_path = os.path.join(seg_videos_folder, image_name.split('.')[0] + '.mp4')\n",
    "    motion_sequence_path_keypoints = os.path.join(keypoint_videos_folder, image_name.split('.')[0] + '.mp4')\n",
    "    \n",
    "    #check if the file doesn't exist\n",
    "    if not os.path.exists(motion_sequence_path):\n",
    "        continue\n",
    "    #\n",
    "\n",
    "    random_seed = 1\n",
    "    sampling_steps = 25\n",
    "    guidance_scale = 7.5\n",
    "    controlnet_weights = [1,1] # segmentation mask, keypoints\n",
    "\n",
    "    # Read the reference image and motion sequence\n",
    "    reference_image = read_image(np.array(Image.open(reference_image_path)))\n",
    "    motion_sequence = read_video(motion_sequence_path)\n",
    "    motion_sequence_keypoints = read_video(motion_sequence_path_keypoints)\n",
    "\n",
    "    result = animator(reference_image, motion_sequence, random_seed, sampling_steps, guidance_scale, motion_sequence_keypoints=motion_sequence_keypoints,\n",
    "                    controlnet_weights=controlnet_weights,\n",
    "                    return_raw_output=True)\n",
    "    \n",
    "    \n",
    "    #save the results\n",
    "    result_path = os.path.join(results_folder, image_name.split('.')[0] + '.png')\n",
    "    from torchvision.utils import save_image\n",
    "    result_ = result[0,:,0]\n",
    "    save_image(result_, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.shape #torch.Size([1, 3, 16, 512, 512])\n",
    "\n",
    "#pick the first frame and show it\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = result[0,:,0] #.permute(1,2,0) #.cpu().numpy()\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "save_image(img, '/home/test/Desktop/Ashok_Project_finalday_results/rajinikanth/first_frame.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this block \n",
    "\n",
    "\n",
    "\n",
    "images_folder = '/home/test/Desktop/good_samples/images'\n",
    "image_names = os.listdir(images_folder)\n",
    "\n",
    "seg_videos_folder = '/home/test/Desktop/good_samples/seg_thin'\n",
    "keypoint_videos_folder = '/home/test/Desktop/good_samples/keypoint_videos'\n",
    "\n",
    "\n",
    "#============ pre-processing ============\n",
    "# if seg,keypoints are images and not videos then convert them to videos\n",
    "\n",
    "#check if images are there in the folder. pick a file. see if ends with mp4 or not. if not then convert to video\n",
    "random_file = os.listdir(seg_videos_folder)[0]\n",
    "if not random_file.endswith('.mp4'):\n",
    "    seg_images_dir = seg_videos_folder\n",
    "    seg_videos_folder = seg_videos_folder+'_videos'\n",
    "    from ashok_utils.video_utils import image_to_video_folder \n",
    "    image_to_video_folder(seg_images_dir, seg_videos_folder, time=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for image_name in image_names: \n",
    "    # # Example inputs\n",
    "    # reference_image_path = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/lab_presentation/lady_standing_540.jpg\"\n",
    "    # motion_sequence_path = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/lab_presentation/seg_videos/segmentation_mask_fat_1.mp4\"\n",
    "    # motion_sequence_path_keypoints = \"/media/test/vcl/ASHOK_PART2/Mtech_Project/DATA/lab_presentation/lady_standing_resized_keypoints_540.mp4\"\n",
    "    \n",
    "    reference_image_path = os.path.join(images_folder, image_name)\n",
    "    motion_sequence_path = os.path.join(seg_videos_folder, image_name.split('.')[0] + '.mp4')\n",
    "    motion_sequence_path_keypoints = os.path.join(keypoint_videos_folder, image_name.split('.')[0] + '.mp4')\n",
    "    \n",
    "    #check if the file doesn't exist\n",
    "    if not os.path.exists(motion_sequence_path):\n",
    "        continue\n",
    "    #\n",
    "\n",
    "    random_seed = 1\n",
    "    sampling_steps = 25\n",
    "    guidance_scale = 7.5\n",
    "    controlnet_weights = [1,0] # segmentation mask, keypoints\n",
    "\n",
    "    # Read the reference image and motion sequence\n",
    "    reference_image = read_image(np.array(Image.open(reference_image_path)))\n",
    "    motion_sequence = read_video(motion_sequence_path)\n",
    "    motion_sequence_keypoints = read_video(motion_sequence_path_keypoints)\n",
    "\n",
    "    result = animator(reference_image, motion_sequence, random_seed, sampling_steps, guidance_scale, motion_sequence_keypoints=motion_sequence_keypoints,\n",
    "                    controlnet_weights=controlnet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manimate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
